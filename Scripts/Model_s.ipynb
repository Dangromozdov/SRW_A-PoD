{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc34b5f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 276 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import psycopg2\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9ceba9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psycopg2.connect(\n",
    " database=\"postgres\", \n",
    " user=\"postgres\", \n",
    " password=\"********\", \n",
    " host=\"localhost\", \n",
    " port=\"****\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f9ba7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_load = pd.read_csv(\"archive/spam_ham_dataset.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0035aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea6adcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = df_load.iloc[999:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e960b0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4446</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: vicodin for you . cheap .\\r\\nyou need...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>305</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: logistics enom team\\r\\nhal , as per o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>688</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: so union\\r\\ntville\\r\\n5031 at tville ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1465</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: september 2000 availabilities\\r\\nthis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1459</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: potential list fo 9 / 00\\r\\ndaren :\\r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "999         4446  spam  Subject: vicodin for you . cheap .\\r\\nyou need...   \n",
       "1000         305   ham  Subject: logistics enom team\\r\\nhal , as per o...   \n",
       "1001         688   ham  Subject: so union\\r\\ntville\\r\\n5031 at tville ...   \n",
       "1002        1465   ham  Subject: september 2000 availabilities\\r\\nthis...   \n",
       "1003        1459   ham  Subject: potential list fo 9 / 00\\r\\ndaren :\\r...   \n",
       "\n",
       "      label_num  \n",
       "999           1  \n",
       "1000          0  \n",
       "1001          0  \n",
       "1002          0  \n",
       "1003          0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0965eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.47 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Подготовим корпус\n",
    "corpus = []\n",
    "stop_words = stopwords.words('english')\n",
    "tok = WordPunctTokenizer()\n",
    "for line in df_class['text'].values:\n",
    "    line1 = line.strip().lower()\n",
    "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
    "    text_tok = tok.tokenize(line1)\n",
    "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
    "    corpus.append(text_tok1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16cee4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['subject',\n",
       "  'vicodin',\n",
       "  'cheap',\n",
       "  'need',\n",
       "  'vicodin',\n",
       "  'get',\n",
       "  'need',\n",
       "  'wait',\n",
       "  'longer',\n",
       "  'unique',\n",
       "  'chance',\n",
       "  'save',\n",
       "  'medications',\n",
       "  'saving',\n",
       "  'boosting',\n",
       "  'health',\n",
       "  'courtesy',\n",
       "  'wristwatch',\n",
       "  'consensus',\n",
       "  'chapel',\n",
       "  'baltimorean',\n",
       "  'halfway',\n",
       "  'debacle',\n",
       "  'torsion',\n",
       "  'hey',\n",
       "  'song',\n",
       "  'staminate',\n",
       "  'spring',\n",
       "  'teledyne',\n",
       "  'freakish',\n",
       "  'becker',\n",
       "  'basswood',\n",
       "  'ben',\n",
       "  'aphelion',\n",
       "  'mileage',\n",
       "  'moulton',\n",
       "  'poetic',\n",
       "  'interstitial',\n",
       "  'godson',\n",
       "  'arctic',\n",
       "  'swelter',\n",
       "  'bust',\n",
       "  'egress',\n",
       "  'nonsensic',\n",
       "  'sectarian',\n",
       "  'caloric',\n",
       "  'qualify',\n",
       "  'embedding',\n",
       "  'expand',\n",
       "  'cupboard',\n",
       "  'splintery',\n",
       "  'macedonia',\n",
       "  'inheritance',\n",
       "  'polyhymnia',\n",
       "  'conceal',\n",
       "  'deathward',\n",
       "  'fingernail',\n",
       "  'suppressor',\n",
       "  'befallen',\n",
       "  'firewall',\n",
       "  'kappa',\n",
       "  'spiral',\n",
       "  'army',\n",
       "  'carcinoma',\n",
       "  'fermat',\n",
       "  'lillian',\n",
       "  'monteverdi',\n",
       "  'salisbury',\n",
       "  'suck',\n",
       "  'scot',\n",
       "  'tendency',\n",
       "  'basin',\n",
       "  'meteoritic',\n",
       "  'dustbin',\n",
       "  'climax',\n",
       "  'anorexia',\n",
       "  'avery',\n",
       "  'luzon',\n",
       "  'nation',\n",
       "  'audrey',\n",
       "  'penance',\n",
       "  'fibrosis',\n",
       "  'carboxylic',\n",
       "  'accept',\n",
       "  'coachwork',\n",
       "  'bennett',\n",
       "  'took',\n",
       "  'demountable',\n",
       "  'bisexual',\n",
       "  'fredholm',\n",
       "  'craggy',\n",
       "  'erwin',\n",
       "  'stove',\n",
       "  'restaurateur',\n",
       "  'mudsling',\n",
       "  'capitol',\n",
       "  'fabulous',\n",
       "  'diamond',\n",
       "  'angie',\n",
       "  'committee',\n",
       "  'tidbit',\n",
       "  'boogie',\n",
       "  'calvert',\n",
       "  'virtue'],\n",
       " ['subject',\n",
       "  'logistics',\n",
       "  'enom',\n",
       "  'team',\n",
       "  'hal',\n",
       "  'per',\n",
       "  'discussion',\n",
       "  'logistics',\n",
       "  'people',\n",
       "  'dedicated',\n",
       "  'enom',\n",
       "  'development',\n",
       "  'key',\n",
       "  'subject',\n",
       "  'experts',\n",
       "  'logistics',\n",
       "  'managers',\n",
       "  'various',\n",
       "  'regions',\n",
       "  'key',\n",
       "  'subject',\n",
       "  'expert',\n",
       "  'pull',\n",
       "  'added',\n",
       "  'resources',\n",
       "  'individual',\n",
       "  'pipeline',\n",
       "  'schedulers',\n",
       "  'really',\n",
       "  'detailed',\n",
       "  'work',\n",
       "  'far',\n",
       "  'time',\n",
       "  'dedicated',\n",
       "  'commit',\n",
       "  'much',\n",
       "  'time',\n",
       "  'needed',\n",
       "  'understanding',\n",
       "  'individuals',\n",
       "  'responsibility',\n",
       "  'managing',\n",
       "  'scheduling',\n",
       "  'activity',\n",
       "  'regions',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  'bid',\n",
       "  'week',\n",
       "  'emergencies',\n",
       "  'develop',\n",
       "  'needed',\n",
       "  'trading',\n",
       "  'desks',\n",
       "  'meetings',\n",
       "  'individuals',\n",
       "  'scheduled',\n",
       "  'afternoon',\n",
       "  'kathy',\n",
       "  'kelly',\n",
       "  'northeast',\n",
       "  'ed',\n",
       "  'terry',\n",
       "  'southeast',\n",
       "  'randy',\n",
       "  'gay',\n",
       "  'west',\n",
       "  'george',\n",
       "  'smith',\n",
       "  'central',\n",
       "  'darren',\n",
       "  'farmer',\n",
       "  'texas',\n",
       "  'project',\n",
       "  'steering',\n",
       "  'team',\n",
       "  'bob',\n",
       "  'superty',\n",
       "  'randy',\n",
       "  'gay',\n",
       "  'george',\n",
       "  'smith',\n",
       "  'discussed',\n",
       "  'might',\n",
       "  'bring',\n",
       "  'others',\n",
       "  'product',\n",
       "  'starts',\n",
       "  'take',\n",
       "  'shape',\n",
       "  'impacting',\n",
       "  'areas',\n",
       "  'global',\n",
       "  'example',\n",
       "  'look',\n",
       "  'forward',\n",
       "  'next',\n",
       "  'meeting',\n",
       "  'thanks',\n",
       "  'bob',\n",
       "  'x'],\n",
       " ['subject',\n",
       "  'union',\n",
       "  'tville',\n",
       "  'tville',\n",
       "  'may',\n",
       "  'total',\n",
       "  'forwarded',\n",
       "  'ami',\n",
       "  'chokshi',\n",
       "  'corp',\n",
       "  'enron',\n",
       "  'pm',\n",
       "  'enron',\n",
       "  'north',\n",
       "  'america',\n",
       "  'corp',\n",
       "  'ami',\n",
       "  'chokshi',\n",
       "  'pm',\n",
       "  'daren',\n",
       "  'j',\n",
       "  'farmer',\n",
       "  'hou',\n",
       "  'ect',\n",
       "  'ect',\n",
       "  'cc',\n",
       "  'subject',\n",
       "  'southern',\n",
       "  'union',\n",
       "  'may',\n",
       "  'st',\n",
       "  'port',\n",
       "  'arthur',\n",
       "  'estimates',\n",
       "  'volumes',\n",
       "  'april',\n",
       "  'ville',\n",
       "  'colorado',\n",
       "  'rs',\n",
       "  'either',\n",
       "  'spot',\n",
       "  'april',\n",
       "  'janet',\n",
       "  'know',\n",
       "  'next',\n",
       "  'month',\n",
       "  'yet',\n",
       "  'total',\n",
       "  'safe',\n",
       "  'assumption'],\n",
       " ['subject',\n",
       "  'september',\n",
       "  'availabilities',\n",
       "  'first',\n",
       "  'file',\n",
       "  'avails',\n",
       "  'devon',\n",
       "  'production',\n",
       "  'sept',\n",
       "  'sure',\n",
       "  'follow',\n",
       "  'thanks',\n",
       "  'beverly',\n",
       "  'forwarded',\n",
       "  'beverly',\n",
       "  'beaty',\n",
       "  'hou',\n",
       "  'ect',\n",
       "  'pm',\n",
       "  'enron',\n",
       "  'capital',\n",
       "  'trade',\n",
       "  'resources',\n",
       "  'corp',\n",
       "  'steve',\n",
       "  'holmes',\n",
       "  'cc',\n",
       "  'cynthia',\n",
       "  'cantrell',\n",
       "  'subject',\n",
       "  'september',\n",
       "  'availabilities',\n",
       "  'attached',\n",
       "  'reflects',\n",
       "  'first',\n",
       "  'month',\n",
       "  'availabilities',\n",
       "  'september',\n",
       "  'send',\n",
       "  'revised',\n",
       "  'copy',\n",
       "  'final',\n",
       "  'numbers',\n",
       "  'soon',\n",
       "  'aware',\n",
       "  'changes',\n",
       "  'thanks',\n",
       "  'steve',\n",
       "  'enronavailso',\n",
       "  'xls'],\n",
       " ['subject',\n",
       "  'potential',\n",
       "  'list',\n",
       "  'fo',\n",
       "  'daren',\n",
       "  'correct',\n",
       "  'meter',\n",
       "  'number',\n",
       "  'north',\n",
       "  'central',\n",
       "  'thanks',\n",
       "  'susan',\n",
       "  'x',\n",
       "  'forwarded',\n",
       "  'susan',\n",
       "  'smith',\n",
       "  'hou',\n",
       "  'ect',\n",
       "  'pm',\n",
       "  'susan',\n",
       "  'smith',\n",
       "  'pm',\n",
       "  'daren',\n",
       "  'j',\n",
       "  'farmer',\n",
       "  'hou',\n",
       "  'ect',\n",
       "  'ect',\n",
       "  'cc',\n",
       "  'vance',\n",
       "  'l',\n",
       "  'taylor',\n",
       "  'hou',\n",
       "  'ect',\n",
       "  'ect',\n",
       "  'melissa',\n",
       "  'graves',\n",
       "  'hou',\n",
       "  'ect',\n",
       "  'ect',\n",
       "  'donald',\n",
       "  'p',\n",
       "  'reinhardt',\n",
       "  'hou',\n",
       "  'ect',\n",
       "  'ect',\n",
       "  'subject',\n",
       "  'potential',\n",
       "  'list',\n",
       "  'fo',\n",
       "  'daren',\n",
       "  'per',\n",
       "  'vance',\n",
       "  'discussion',\n",
       "  'deal',\n",
       "  'makers',\n",
       "  'following',\n",
       "  'potential',\n",
       "  'deals',\n",
       "  'included',\n",
       "  'vance',\n",
       "  'number',\n",
       "  'north',\n",
       "  'central',\n",
       "  'mcmurrey',\n",
       "  'meter',\n",
       "  'mid',\n",
       "  'month',\n",
       "  'mcfd',\n",
       "  'approx',\n",
       "  'gas',\n",
       "  'daily',\n",
       "  'helmrich',\n",
       "  'payne',\n",
       "  'ballard',\n",
       "  'new',\n",
       "  'meter',\n",
       "  'mid',\n",
       "  'month',\n",
       "  'mcfd',\n",
       "  'approx',\n",
       "  'gas',\n",
       "  'daily',\n",
       "  'kcs',\n",
       "  'resources',\n",
       "  'dickenson',\n",
       "  'bayou',\n",
       "  'meter',\n",
       "  'midmonth',\n",
       "  'mcfd',\n",
       "  'approx',\n",
       "  'gas',\n",
       "  'daily',\n",
       "  'let',\n",
       "  'us',\n",
       "  'know',\n",
       "  'need',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'susan',\n",
       "  'smith',\n",
       "  'x']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddd61b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.48 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Обучаем модель word2vec на нашем корпусе\n",
    "model_dz = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdcfbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('look', 0.9450597167015076), ('want', 0.9429246783256531), ('leave', 0.9421932697296143), ('someone', 0.9355387091636658), ('able', 0.9337681531906128)]\n"
     ]
    }
   ],
   "source": [
    "# Проверим, что модель обучилась\n",
    "print(model_dz.wv.most_similar(positive=['find'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "093ff4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class EmbeddingVectorizer(object):\n",
    "    '''\n",
    "    Для текста усредним вектора входящих в него слов\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.size = model.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean(\n",
    "            [self.model[w] for w in words if w in self.model] \n",
    "            or [np.zeros(self.size)], axis=0)\n",
    "            for words in X])\n",
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))\n",
    "def spam(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cea9c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучающая и тестовая выборки\n",
    "boundary = 3000\n",
    "X_train = corpus[:boundary] \n",
    "X_test = corpus[boundary:]\n",
    "y_train = df_class.label.values[:boundary]\n",
    "y_test = df_class.label.values[boundary:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0c970aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "ham \t 0.9741379310344828\n",
      "spam \t 0.9\n",
      "CPU times: total: 1.14 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2vecKNN = spam(EmbeddingVectorizer(model_dz.wv), KNeighborsClassifier(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "889d53e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'spam' 'ham' 'ham' 'spam'\n",
      " 'ham' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam'\n",
      " 'ham' 'spam' 'spam' 'ham' 'spam' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam'\n",
      " 'spam' 'spam' 'spam' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham']\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exmpl = []\n",
    "for i in range(100):\n",
    "    val = df_load.iloc[i, 2]\n",
    "    val1 = val.strip().lower()\n",
    "    val1 = re.sub(\"[^a-zA-Z]\",\" \", val1)\n",
    "    val1_tok = tok.tokenize(val1)\n",
    "    val1_tok1 = [w for w in val1_tok if not w in stop_words]\n",
    "    exmpl.append(val1_tok1)\n",
    "print(word2vecKNN.predict(exmpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f48aeaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT id, text FROM class WHERE date BETWEEN '2022-09-17' AND '2022-09-19'\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = 'class'\n",
    "day1 = '2022-09-17'\n",
    "day2 = '2022-09-19'\n",
    "sql_class = \"SELECT id, text FROM \"+t+ \" WHERE date BETWEEN '\" + str(day1)+\"' AND '\"+ str(day2)+\"'\"\n",
    "print(sql_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7e0dd6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_class = pd.read_sql_query(sql_class, con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "704ea692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>820</td>\n",
       "      <td>Subject: get that new car 8434\\r\\npeople nowth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>821</td>\n",
       "      <td>Subject: deals 141877 , 141883 , and 141884 ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822</td>\n",
       "      <td>Subject: tenaska iv\\r\\nrick ,\\r\\nattached are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>823</td>\n",
       "      <td>Subject: enron / hpl actuals for january 3 , 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>824</td>\n",
       "      <td>Subject: electronic pay stubs\\r\\nget ready . b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text\n",
       "0  820  Subject: get that new car 8434\\r\\npeople nowth...\n",
       "1  821  Subject: deals 141877 , 141883 , and 141884 ( ...\n",
       "2  822  Subject: tenaska iv\\r\\nrick ,\\r\\nattached are ...\n",
       "3  823  Subject: enron / hpl actuals for january 3 , 2...\n",
       "4  824  Subject: electronic pay stubs\\r\\nget ready . b..."
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "577f05f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'spam' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'ham' 'ham' 'spam' 'ham']\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exmpl = []\n",
    "for i in range(29):\n",
    "    val = df_class.iloc[i, 1]\n",
    "    val1 = val.strip().lower()\n",
    "    val1 = re.sub(\"[^a-zA-Z]\",\" \", val1)\n",
    "    val1_tok = tok.tokenize(val1)\n",
    "    val1_tok1 = [w for w in val1_tok if not w in stop_words]\n",
    "    exmpl.append(val1_tok1)\n",
    "print(word2vecKNN.predict(exmpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2ba0bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class[\"length\"] = \"\"\n",
    "for i in range(len(df_class)):\n",
    "    df_class.iloc[i, 2] = len(df_class.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65aaf672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>820</td>\n",
       "      <td>Subject: get that new car 8434\\r\\npeople nowth...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>821</td>\n",
       "      <td>Subject: deals 141877 , 141883 , and 141884 ( ...</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822</td>\n",
       "      <td>Subject: tenaska iv\\r\\nrick ,\\r\\nattached are ...</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>823</td>\n",
       "      <td>Subject: enron / hpl actuals for january 3 , 2...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>824</td>\n",
       "      <td>Subject: electronic pay stubs\\r\\nget ready . b...</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text length\n",
       "0  820  Subject: get that new car 8434\\r\\npeople nowth...    174\n",
       "1  821  Subject: deals 141877 , 141883 , and 141884 ( ...    648\n",
       "2  822  Subject: tenaska iv\\r\\nrick ,\\r\\nattached are ...   1182\n",
       "3  823  Subject: enron / hpl actuals for january 3 , 2...    107\n",
       "4  824  Subject: electronic pay stubs\\r\\nget ready . b...   1078"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9fb92bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45728\n"
     ]
    }
   ],
   "source": [
    "x = df_class[\"length\"].sum()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a40af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
